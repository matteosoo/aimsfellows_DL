{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sketcher_traditional_chinese_char.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteosoo/aimsfellows_DL/blob/master/project/sketcher_template/sketcher_traditional_chinese_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV8HjB12sFTr"
      },
      "source": [
        "# sketcher_traditional_chinese_char\n",
        "- Reference: https://github.com/zaidalyafeai/zaidalyafeai.github.io/tree/master/sketcher \n",
        "- 將繁體手寫字做手繪辨識"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM9gm06Ksn8B"
      },
      "source": [
        "##  Mount the Google drive to colab\n",
        "- Note\n",
        "  - !ls 可以將自己目前的資料夾給show出來\n",
        "  - !cd 表示change direct，讓你所執行的根目錄，轉換到quick_draw這個資料夾\n",
        "- p.s. 請根據自己擺放在雲端硬碟的路徑做適當的調變"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzNLe_wx1tzj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qODtjPSa2CbF"
      },
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks/quick_draw/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SR3XP9r2EVd"
      },
      "source": [
        "!cd '/content/drive/My Drive/Colab Notebooks/quick_draw/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4cy1tZctoYY"
      },
      "source": [
        "## Import package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILfY9o7RtPpQ"
      },
      "source": [
        "# 1.15.2為助教在測試本專案後，建議各位同學使用的版本\n",
        "!pip install tensorflow==1.15.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgRtqA9a2GZd"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "print(tf.__version__) # print出目前使用的tensorflow版本"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGTYPv9AAvyp"
      },
      "source": [
        "## Load the Data\n",
        "- Note\n",
        "  - 這邊的mini_classes.txt要自己建檔，放所要訓練用到的字\n",
        "  - utf8解碼是可以使中文字的檔名在解碼過程中不會變為亂碼編碼\n",
        "  - readline()為一行一行讀，所以在建檔時務必確保用enter換行，不要多也不要少\n",
        "  - HandWritting_npy資料夾下必須自己去查詢如何轉換資料，才能正確使用第2個cell所寫的load_data() function\n",
        "  - 也要注意image_size我們已幫各位從原專案28轉成300，因為過低的解析度可能不利於辨識繁體字的複雜"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGTY-skK3aGJ"
      },
      "source": [
        "classes = []\n",
        "with open('mini_classes.txt', 'r', encoding='utf8') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        line = line.strip('\\n')\n",
        "        classes.append(line)\n",
        "\n",
        "print(len(classes))\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHZTBVNL2GcV"
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 90000])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(tqdm(all_files)):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAz6k3u26Xpx"
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('HandWritting_npy')\n",
        "num_classes = len(class_names)\n",
        "image_size = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn9mgC-_7Bmb"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FNqhgGDC8fu"
      },
      "source": [
        "Show some random data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcOXJ_vbDOzI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(300,300))  # reshape這邊只是show出來的比例所以不影響訓練\n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIwZ5f-MDnH4"
      },
      "source": [
        "## Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh1zezko2GiO"
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mhzP67xDviK"
      },
      "source": [
        "## The Model\n",
        "- Note\n",
        "  - 最後一層的網路是藉接分類的，所以請思考該如何給下正確的參數\n",
        "  - 想要優化，網路架構的設計也往往是一大重點"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFCbqnAGEN2Z"
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.train.AdamOptimizer()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oU-v7-GD0uG"
      },
      "source": [
        "## Training\n",
        "- Note\n",
        "  - 上課有教導overfitting的概念，所以我們知道不能過度訓練\n",
        "  - 反而言之，我們應該如何調整，讓這個model能夠fit到最好的accuracy呢?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6jb1xL97LP6"
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=1, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdV0Zd0IEHUc"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8iQOfnQ7LS8"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HLOXeciFnNn"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_uuUqnK7LVa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze())\n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDncGXWuFsYV"
      },
      "source": [
        "## Store the classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSODL_db7bce"
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRrg_F86F0l3"
      },
      "source": [
        "## Install TensorFlowJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5DxKIRc7jwY"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP_hL1BJF43E"
      },
      "source": [
        "## Save model and Convert to tensorflowJS\n",
        "- Note\n",
        "  - !mkdir 是一個讓你在目前的資料夾下創建一個新資料夾(名為model3)的指令\n",
        "  - !cp為copy一file到另一個\n",
        "目的地file\n",
        "  - 最後我們將model3的資料夾整包壓縮(zip)並下載下來就完成了"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9tbZ4OA8bid"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReYDcUlR8dNl"
      },
      "source": [
        "!mkdir model3\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTVTk8BR8dQs"
      },
      "source": [
        "!cp class_names.txt model3/class_names.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kodsmYrs8dT2"
      },
      "source": [
        "!zip -r model3.zip model3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU5p8DGQ8dWc"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model3.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}